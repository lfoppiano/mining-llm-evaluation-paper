@article{kokon2023chatgpt,
	title        = {{ChatGPT}: Jack of all trades, master of none},
	author       = {Jan Koco{\'{n}} and Igor Cichecki and Oliwier Kaszyca and Mateusz Kochanek and Dominika Szyd{\l}o and Joanna Baran and Julita Bielaniewicz and Marcin Gruza and Arkadiusz Janz and Kamil Kanclerz and Anna Koco{\'{n}} and Bart{\l}omiej Koptyra and Wiktoria Mieleszczenko-Kowszewicz and Piotr Mi{\l}kowski and Marcin Oleksy and Maciej Piasecki and {\L}ukasz Radli{\'{n}}ski and Konrad Wojtasik and Stanis{\l}aw Wo{\'{z}}niak and Przemys{\l}aw Kazienko},
	year         = 2023,
	month        = {nov},
	journal      = {Information Fusion},
	publisher    = {Elsevier {BV}},
	volume       = 99,
	pages        = 101861,
	doi          = {10.1016/j.inffus.2023.101861},
	url          = {https://doi.org/10.1016%2Fj.inffus.2023.101861}
}
@misc{moradi2022gpt3,
	title        = {GPT-3 Models are Poor Few-Shot Learners in the Biomedical Domain},
	author       = {Milad Moradi and Kathrin Blagec and Florian Haberl and Matthias Samwald},
	year         = 2022,
	eprint       = {2109.02555},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}
@article{hoffmann2022training,
	title        = {Training Compute-optimal Large Language Models},
	author       = {Hoffmann, J. and Borgeaud, S. and Arthur, M. and Buchatskaya, E. and Cai, T. Y. and Eliza, R. and Sifre, L.},
	year         = 2022,
	doi          = {10.48550/arxiv.2203.15556}
}
@article{risch2021semantic,
	title        = {Semantic answer similarity for evaluating question answering models},
	author       = {Risch, J. and Möller, T. and Gutsch, J. and Pietsch, M.},
	year         = 2021,
	journal      = {Proceedings of the 3rd Workshop on Machine Reading for Question Answering},
	doi          = {10.18653/v1/2021.mrqa-1.15}
}
@inproceedings{harper2021semeval,
	title        = {{S}em{E}val-2021 Task 8: {M}eas{E}val {--} Extracting Counts and Measurements and their Related Contexts},
	author       = {Harper, Corey  and Cox, Jessica  and Kohler, Curt  and Scerri, Antony  and Daniel Jr., Ron  and Groth, Paul},
	year         = 2021,
	month        = aug,
	booktitle    = {Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021)},
	publisher    = {Association for Computational Linguistics},
	address      = {Online},
	pages        = {306--316},
	doi          = {10.18653/v1/2021.semeval-1.38},
	url          = {https://aclanthology.org/2021.semeval-1.38},
	abstract     = {We describe MeasEval, a SemEval task of extracting counts, measurements, and related context from scientific documents, which is of significant importance to the creation of Knowledge Graphs that distill information from the scientific literature. This is a new task in 2021, for which over 75 submissions from 25 participants were received. We expect the data developed for this task and the findings reported to be valuable to the scientific knowledge extraction, metrology, and automated knowledge base construction communities.}
}
@article{tang2023struc,
	title        = {Struc-Bench: Are Large Language Models Really Good at Generating Complex Structured Data?},
	author       = {Tang, Xiangru and Zong, Yiming and Zhao, Yilun and Cohan, Arman and Gerstein, Mark},
	year         = 2023,
	journal      = {arXiv preprint arXiv:2309.08963}
}
@article{gonzalez2023yes,
	title        = {Yes but.. Can ChatGPT identify entities in historical documents?},
	author       = {Gonz{\'a}lez-Gallardo, Carlos-Emiliano and Boros, Emanuela and Girdhar, Nancy and Hamdi, Ahmed and Moreno, Jose G and Doucet, Antoine},
	year         = 2023,
	journal      = {arXiv preprint arXiv:2303.17322}
}
@article{ma2023large,
	title        = {Large language model is not a good few-shot information extractor, but a good reranker for hard samples!},
	author       = {Ma, Y. and Cao, Y. and Hong, Y. and Sun, A.},
	year         = 2023,
	doi          = {10.48550/arxiv.2303.08559}
}
@inproceedings{lin2023llmeval,
	title        = {{LLM}-Eval: Unified Multi-Dimensional Automatic Evaluation for Open-Domain Conversations with Large Language Models},
	author       = {Lin, Yen-Ting  and Chen, Yun-Nung},
	year         = 2023,
	month        = jul,
	booktitle    = {Proceedings of the 5th Workshop on NLP for Conversational AI (NLP4ConvAI 2023)},
	publisher    = {Association for Computational Linguistics},
	address      = {Toronto, Canada},
	pages        = {47--58},
	doi          = {10.18653/v1/2023.nlp4convai-1.5},
	url          = {https://aclanthology.org/2023.nlp4convai-1.5},
	abstract     = {We propose LLM-Eval, a unified multi-dimensional automatic evaluation method for open-domain conversations with large language models (LLMs). Existing evaluation methods often rely on human annotations, ground-truth responses, or multiple LLM prompts, which can be expensive and time-consuming. To address these issues, we design a single prompt-based evaluation method that leverages a unified evaluation schema to cover multiple dimensions of conversation quality in a single model call. We extensively evaluate the performance of LLM-Eval on various benchmark datasets, demonstrating its effectiveness, efficiency, and adaptability compared to state-of-the-art evaluation methods. Our analysis also highlights the importance of choosing suitable LLMs and decoding strategies for accurate evaluation results. LLM-Eval offers a versatile and robust solution for evaluating open-domain conversation systems, streamlining the evaluation process and providing consistent performance across diverse scenarios.}
}
@article{reimers2019sentencebert,
	title        = {sentence-bert: sentence embeddings using siamese bert-networks},
	author       = {Reimers, N. and Gurevych, I.},
	year         = 2019,
	doi          = {10.18653/v1/d19-1410}
}
@inproceedings{beltagy2020scibert,
	title        = {{S}ci{BERT}: A Pretrained Language Model for Scientific Text},
	author       = {Beltagy, Iz  and Lo, Kyle  and Cohan, Arman},
	year         = 2019,
	month        = nov,
	booktitle    = {Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
	publisher    = {Association for Computational Linguistics},
	address      = {Hong Kong, China},
	pages        = {3615--3620},
	doi          = {10.18653/v1/D19-1371},
	url          = {https://aclanthology.org/D19-1371},
	abstract     = {Obtaining large-scale annotated data for NLP tasks in the scientific domain is challenging and expensive. We release SciBERT, a pretrained language model based on BERT (Devlin et. al., 2018) to address the lack of high-quality, large-scale labeled scientific data. SciBERT leverages unsupervised pretraining on a large multi-domain corpus of scientific publications to improve performance on downstream scientific NLP tasks. We evaluate on a suite of tasks including sequence tagging, sentence classification and dependency parsing, with datasets from a variety of scientific domains. We demonstrate statistically significant improvements over BERT and achieve new state-of-the-art results on several of these tasks. The code and pretrained models are available at https://github.com/allenai/scibert/.}
}
@article{yasunaga2020linkbert,
	title        = {Linkbert: pretraining language models with document links},
	author       = {Yasunaga, M. and Leskovec, J. and Liang, P.},
	year         = 2022,
	doi          = {10.48550/arxiv.2203.15827}
}
@misc{jin2023large,
	title        = {Can Large Language Models Infer Causation from Correlation?},
	author       = {Zhijing Jin and Jiarui Liu and Zhiheng Lyu and Spencer Poff and Mrinmaya Sachan and Rada Mihalcea and Mona Diab and Bernhard Schölkopf},
	year         = 2023,
	eprint       = {2306.05836},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}
@article{lfoppiano2021supermat,
	title        = {Supermat: construction of a linked annotated dataset from superconductors-related publications},
	author       = {Foppiano, L. and Dieb, T. and Suzuki, A. and Castro, P. and Iwasaki, S. and Uzuki, A. and Echevarria, M. and Meng, Y. and Terashima, K. and Romary, L. and Takano, Y. and Ishii, M.},
	year         = 2021,
	journal      = {Science and Technology of Advanced Materials Methods},
	volume       = 1,
	pages        = {34--44},
	doi          = {10.1080/27660400.2021.1918396},
	issue        = 1
}
@article{lfoppiano2023automatic,
	title        = {Automatic extraction of materials and properties from superconductors scientific literature},
	author       = {Foppiano, L. and Castro, P. and Suarez, P. and Terashima, K. and Takano, Y. and Ishii, M.},
	year         = 2023,
	journal      = {Science and Technology of Advanced Materials Methods},
	volume       = 3,
	doi          = {10.1080/27660400.2022.2153633},
	issue        = 1
}
@misc{min2023factscore,
	title        = {FActScore: Fine-grained Atomic Evaluation of Factual Precision in Long Form Text Generation},
	author       = {Sewon Min and Kalpesh Krishna and Xinxi Lyu and Mike Lewis and Wen-tau Yih and Pang Wei Koh and Mohit Iyyer and Luke Zettlemoyer and Hannaneh Hajishirzi},
	year         = 2023,
	eprint       = {2305.14251},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}
@inproceedings{harper2021semeval2021,
	title        = {{S}em{E}val-2021 Task 8: {M}eas{E}val {--} Extracting Counts and Measurements and their Related Contexts},
	author       = {Harper, Corey  and Cox, Jessica  and Kohler, Curt  and Scerri, Antony  and Daniel Jr., Ron  and Groth, Paul},
	year         = 2021,
	month        = aug,
	booktitle    = {Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021)},
	publisher    = {Association for Computational Linguistics},
	address      = {Online},
	pages        = {306--316},
	doi          = {10.18653/v1/2021.semeval-1.38},
	url          = {https://aclanthology.org/2021.semeval-1.38},
	editor       = {Palmer, Alexis  and Schneider, Nathan  and Schluter, Natalie  and Emerson, Guy  and Herbelot, Aurelie  and Zhu, Xiaodan},
	abstract     = {We describe MeasEval, a SemEval task of extracting counts, measurements, and related context from scientific documents, which is of significant importance to the creation of Knowledge Graphs that distill information from the scientific literature. This is a new task in 2021, for which over 75 submissions from 25 participants were received. We expect the data developed for this task and the findings reported to be valuable to the scientific knowledge extraction, metrology, and automated knowledge base construction communities.}
}
@article{hatakeyama2023prompt,
	title        = {Prompt engineering of GPT-4 for chemical research: what can/cannot be done?},
	author       = {Kan Hatakeyama-Sato and Naoki Yamane and Yasuhiko Igarashi and Yuta Nabae and Teruaki Hayakawa},
	year         = 2023,
	journal      = {Science and Technology of Advanced Materials: Methods},
	publisher    = {Taylor & Francis},
	volume       = 3,
	number       = 1,
	pages        = 2260300,
	doi          = {10.1080/27660400.2023.2260300},
	url          = {https://doi.org/10.1080/27660400.2023.2260300},
	eprint       = {https://doi.org/10.1080/27660400.2023.2260300}
}
@article{taylor2022galactica,
	title        = {Galactica: A large language model for science},
	author       = {Taylor, Ross and Kardas, Marcin and Cucurull, Guillem and Scialom, Thomas and Hartshorn, Anthony and Saravia, Elvis and Poulton, Andrew and Kerkez, Viktor and Stojnic, Robert},
	year         = 2022,
	journal      = {arXiv preprint arXiv:2211.09085}
}
@inproceedings{foppiano2019quantities,
	title        = {Automatic Identification and Normalisation of Physical Measurements in Scientific Literature},
	author       = {Foppiano, Luca and Romary, Laurent and Ishii, Masashi and Tanifuji, Mikiko},
	year         = 2019,
	booktitle    = {Proceedings of the ACM Symposium on Document Engineering 2019},
	location     = {Berlin, Germany},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {DocEng '19},
	doi          = {10.1145/3342558.3345411},
	isbn         = 9781450368872,
	url          = {https://doi.org/10.1145/3342558.3345411},
	abstract     = {We present Grobid-quantities, an open-source application for extracting and normalising measurements from scientific and patent literature. Tools of this kind, aiming to understand and make unstructured information accessible, represent the building blocks for large-scale Text and Data Mining (TDM) systems. Grobid-quantities is a module built on top of Grobid [6] [13], a machine learning framework for parsing and structuring PDF documents. Designed to process large quantities of data, it provides a robust implementation accessible in batch mode or via a REST API. The machine learning engine architecture follows the cascade approach, where each model is specialised in the resolution of a specific task. The models are trained using CRF (Conditional Random Field) algorithm [12] for extracting quantities (atomic values, intervals and lists), units (such as length, weight) and different value representations (numeric, alphabetic or scientific notation). Identified measurements are normalised according to the International System of Units (SI). Thanks to its stable recall and reliable precision, Grobid-quantities has been integrated as the measurement-extraction engine in various TDM projects, such as Marve (Measurement Context Extraction from Text), for extracting semantic measurements and meaning in Earth Science [10]. At the National Institute for Materials Science in Japan (NIMS), it is used in an ongoing project to discover new superconducting materials. Normalised materials characteristics (such as critical temperature, pressure) extracted from scientific literature are a key resource for materials informatics (MI) [9].},
	articleno    = 24,
	numpages     = 4,
	keywords     = {Physical quantities, Measurements, Units of measurements, TDM, Machine Learning}
}
@misc{openai2023gpt4,
	title        = {GPT-4 Technical Report},
	author       = {OpenAI},
	year         = 2023,
	eprint       = {2303.08774},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}
@article{lee2020patent,
	title        = {Patent claim generation by fine-tuning OpenAI GPT-2},
	author       = {Lee, Jieh-Sheng and Hsiang, Jieh},
	year         = 2020,
	journal      = {World Patent Information},
	publisher    = {Elsevier},
	volume       = 62,
	pages        = 101983
}

@article{dou2021gpt,
  title={Is GPT-3 text indistinguishable from human text? SCARECROW: A framework for scrutinizing machine text},
  author={Dou, Yao and Forbes, Maxwell and Koncel-Kedziorski, Rik and Smith, Noah A and Choi, Yejin},
  journal={arXiv preprint arXiv:2107.01294},
  year={2021}
}


@inproceedings{wu2023exploring,
  title={Exploring Prompt Engineering with GPT Language Models for Document-Level Machine Translation: Insights and Findings},
  author={Wu, Yangjian and Hu, Gang},
  booktitle={Proceedings of the Eighth Conference on Machine Translation},
  pages={166--169},
  year={2023}
}

@misc{ouyang2022training,
      title={Training language models to follow instructions with human feedback}, 
      author={Long Ouyang and Jeff Wu and Xu Jiang and Diogo Almeida and Carroll L. Wainwright and Pamela Mishkin and Chong Zhang and Sandhini Agarwal and Katarina Slama and Alex Ray and John Schulman and Jacob Hilton and Fraser Kelton and Luke Miller and Maddie Simens and Amanda Askell and Peter Welinder and Paul Christiano and Jan Leike and Ryan Lowe},
      year={2022},
      eprint={2203.02155},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{hatakeyama2023using,
  title={Using GPT-4 in parameter selection of polymer informatics: improving predictive accuracy amidst data scarcity and ‘Ugly Duckling’dilemma},
  author={Hatakeyama-Sato, Kan and Watanabe, Seigo and Yamane, Naoki and Igarashi, Yasuhiko and Oyaizu, Kenichi},
  journal={Digital Discovery},
  volume={2},
  number={5},
  pages={1548--1557},
  year={2023},
  publisher={Royal Society of Chemistry}
}


@article{zhang2023one,
  title={One small step for generative ai, one giant leap for agi: A complete survey on chatgpt in aigc era},
  author={Zhang, Chaoning and Zhang, Chenshuang and Li, Chenghao and Qiao, Yu and Zheng, Sheng and Dam, Sumit Kumar and Zhang, Mengchun and Kim, Jung Uk and Kim, Seong Tae and Choi, Jinwoo and others},
  journal={arXiv preprint arXiv:2304.06488},
  year={2023}
}

@article{yao2023tree,
  title={Tree of thoughts: Deliberate problem solving with large language models},
  author={Yao, Shunyu and Yu, Dian and Zhao, Jeffrey and Shafran, Izhak and Griffiths, Thomas L and Cao, Yuan and Narasimhan, Karthik},
  journal={arXiv preprint arXiv:2305.10601},
  year={2023}
}


@article{valmeekam2023planning,
  title={On the Planning Abilities of Large Language Models--A Critical Investigation},
  author={Valmeekam, Karthik and Marquez, Matthew and Sreedharan, Sarath and Kambhampati, Subbarao},
  journal={arXiv preprint arXiv:2305.15771},
  year={2023}
}


@article{sun2023pearl,
  title={PEARL: Prompting Large Language Models to Plan and Execute Actions Over Long Documents},
  author={Sun, Simeng and Liu, Yang and Wang, Shuohang and Zhu, Chenguang and Iyyer, Mohit},
  journal={arXiv preprint arXiv:2305.14564},
  year={2023}
}
